from datetime import datetime, timedelta
import psycopg2
import os

from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.operators.python import PythonOperator, ShortCircuitOperator
from airflow.operators.empty import EmptyOperator

# ============================================================================
#   DAG DE MISE √Ä JOUR ET PR√âDICTION - EX√âCUTION R√âGULI√àRE
# ============================================================================
# 
# üéØ CE DAG S'EX√âCUTE TOUTES LES 6 HEURES ET G√àRE:
# 
# 1Ô∏è‚É£ Backfill m√©t√©o des 6 derni√®res heures (donn√©es r√©elles)
# 2Ô∏è‚É£ G√©n√©ration √©nergie des 6 derni√®res heures (donn√©es historiques)
# 3Ô∏è‚É£ Calcul √©tat R√âEL batteries (6h pass√©es, is_predicted=FALSE)
# 4Ô∏è‚É£ Mise √† jour pr√©visions m√©t√©o (7 jours futurs)
# 5Ô∏è‚É£ Pr√©diction consommation √©nergie (7 jours futurs)
# 6Ô∏è‚É£ Pr√©diction production solaire + batteries (7 jours futurs, is_predicted=TRUE)
# 
# ‚ö†Ô∏è  Ce DAG n√©cessite que le DAG d'initialisation ait √©t√© ex√©cut√©
# ============================================================================

def get_db_connection():
    """Cr√©e une connexion √† la base de donn√©es PostgreSQL"""
    # En environnement Docker, utiliser le nom du service, pas localhost
    host = os.getenv("GAUSSDB_HOST")
    if not host or host == "localhost":
        # Essayer le nom du service PostgreSQL dans docker-compose
        # Adapter selon votre configuration
        host = os.getenv("POSTGRES_HOST", "postgres")
    
    print(f"üîó Tentative de connexion √†: {host}:{os.getenv('GAUSSDB_PORT', '5432')}")
    
    return psycopg2.connect(
        host=host,
        port=os.getenv("GAUSSDB_PORT", "5432"),
        database=os.getenv("GAUSSDB_DB_SILVER", "silver"),
        user=os.getenv("GAUSSDB_USER", "postgres"),
        password=os.getenv("GAUSSDB_PASSWORD", "postgres"),
        sslmode=os.getenv("GAUSSDB_SSLMODE", "disable")
    )

def check_initialization(**context):
    """
    V√©rifie que l'initialisation a √©t√© compl√©t√©e.
    Retourne True si initialis√©, False sinon (ce qui arr√™te le DAG).
    """
    conn = None
    cur = None
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        
        print("=" * 80)
        print("‚úÖ Connexion √† la base de donn√©es √©tablie")
        print("=" * 80)
        
        # V√©rifier si la table de m√©tadonn√©es existe
        cur.execute("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_name = 'pipeline_metadata'
            )
        """)
        table_exists = cur.fetchone()[0]
        
        if not table_exists:
            print("=" * 80)
            print("‚ùå Table pipeline_metadata n'existe pas")
            print("‚ö†Ô∏è  Veuillez ex√©cuter le DAG 'initialization_pipeline' d'abord")
            print("=" * 80)
            return False
        
        # V√©rifier le flag d'initialisation
        cur.execute("""
            SELECT value FROM pipeline_metadata 
            WHERE key = 'initialization_complete'
        """)
        row = cur.fetchone()
        
        if row and row[0] == 'true':
            print("=" * 80)
            print("‚úÖ BASE DE DONN√âES INITIALIS√âE - Ex√©cution du pipeline de mise √† jour")
            print("=" * 80)
            return True
        else:
            print("=" * 80)
            print("‚ùå BASE DE DONN√âES NON INITIALIS√âE")
            print("‚ö†Ô∏è  Veuillez ex√©cuter le DAG 'initialization_pipeline' d'abord")
            print("=" * 80)
            return False
            
    except Exception as e:
        print("=" * 80)
        print(f"‚ùå Erreur lors de la v√©rification: {e}")
        print("‚ö†Ô∏è  Veuillez ex√©cuter le DAG 'initialization_pipeline' d'abord")
        print("=" * 80)
        import traceback
        traceback.print_exc()
        return False
    finally:
        if cur:
            cur.close()
        if conn:
            conn.close()

default_args = {
    "owner": "hamza",
    "depends_on_past": False,
    "email_on_failure": False,
    "email_on_retry": False,
    "retries": 2,
    "retry_delay": timedelta(minutes=5),
}

with DAG(
    dag_id="update_and_prediction_pipeline",
    description="Mise √† jour 6h + Pr√©dictions 7 jours (n√©cessite initialisation)",
    default_args=default_args,
    start_date=datetime(2025, 11, 11),
    schedule_interval="0 */6 * * *",  # Toutes les 6 heures
    catchup=False,
    max_active_runs=1,
    tags=["renewstation", "update", "prediction", "regular"],
) as dag:

    # ========================================================================
    #   V√âRIFICATION PR√âALABLE
    # ========================================================================
    
    check_init = ShortCircuitOperator(
        task_id="check_initialization",
        python_callable=check_initialization,
        provide_context=True,
    )
    
    start_update = EmptyOperator(task_id="start_update")
    
    # ========================================================================
    #   PARTIE 1: MISE √Ä JOUR DONN√âES HISTORIQUES (6H)
    # ========================================================================
    
    # 1. Backfill m√©t√©o des 6 derni√®res heures avec archive
    recent_weather_backfill = BashOperator(
        task_id="weather_backfill_6h",
        bash_command=(
            "cd /opt/airflow && "
            "PYTHONPATH=/opt/airflow "
            "python -m src.pipeline.generator.weather_forecasting --mode recent"
        ),
        execution_timeout=timedelta(minutes=5),
    )
    
    # 2. G√©n√©ration √©nergie pour les 6 derni√®res heures
    recent_energy_backfill = BashOperator(
        task_id="energy_backfill_6h",
        bash_command=(
            "cd /opt/airflow && "
            "PYTHONPATH=/opt/airflow "
            "python -m src.pipeline.generator.backfill_energy_last_6h"
        ),
        execution_timeout=timedelta(minutes=10),
    )
    
    # 3. Calcul √©tat R√âEL batteries (6h pass√©es, is_predicted=FALSE)
    recent_solar_battery_real = BashOperator(
        task_id="solar_battery_real_6h",
        bash_command=(
            "cd /opt/airflow && "
            "PYTHONPATH=/opt/airflow "
            "python -m src.pipeline.generator.solar_battery --mode recent"
        ),
        execution_timeout=timedelta(minutes=10),
    )
    
    historical_complete = EmptyOperator(
        task_id="historical_update_complete",
        trigger_rule="none_failed",
    )
    
    # ========================================================================
    #   PARTIE 2: PR√âDICTIONS (7 JOURS FUTURS)
    # ========================================================================
    
    # 4. Mise √† jour pr√©visions m√©t√©o (7 jours futurs)
    update_weather_forecast = BashOperator(
        task_id="weather_forecast_7d",
        bash_command=(
            "cd /opt/airflow && "
            "PYTHONPATH=/opt/airflow "
            "python -m src.pipeline.generator.weather_forecasting --mode full"
        ),
        execution_timeout=timedelta(minutes=5),
    )
    
    # 5. Pr√©diction consommation √©nergie (7 jours futurs)
    predict_energy_consumption = BashOperator(
        task_id="predict_energy_7d",
        bash_command=(
            "cd /opt/airflow && "
            "PYTHONPATH=/opt/airflow "
            "python -m src.pipeline.generator.prediction"
        ),
        execution_timeout=timedelta(minutes=10),
    )
    
    # 6. Pr√©diction production solaire + batteries (7 jours futurs, is_predicted=TRUE)
    predict_solar_battery = BashOperator(
        task_id="predict_solar_battery_7d",
        bash_command=(
            "cd /opt/airflow && "
            "PYTHONPATH=/opt/airflow "
            "python -m src.pipeline.generator.solar_battery --mode predicted"
        ),
        execution_timeout=timedelta(minutes=15),
    )
    
    predictions_complete = EmptyOperator(
        task_id="predictions_complete",
        trigger_rule="none_failed",
    )
    
    # ========================================================================
    #   FINALISATION
    # ========================================================================
    
    pipeline_complete = EmptyOperator(
        task_id="pipeline_complete",
        trigger_rule="none_failed_min_one_success",
    )
    
    # ========================================================================
    #   D√âPENDANCES
    # ========================================================================
    
    # V√©rification puis d√©marrage
    check_init >> start_update
    
    # PARTIE 1: Mise √† jour historique (parall√®le apr√®s m√©t√©o)
    start_update >> recent_weather_backfill
    recent_weather_backfill >> [recent_energy_backfill, recent_solar_battery_real]
    [recent_energy_backfill, recent_solar_battery_real] >> historical_complete
    
    # PARTIE 2: Pr√©dictions (s√©quentiel)
    historical_complete >> update_weather_forecast
    update_weather_forecast >> predict_energy_consumption
    predict_energy_consumption >> predict_solar_battery
    predict_solar_battery >> predictions_complete
    
    # Finalisation
    predictions_complete >> pipeline_complete


# ============================================================================
#   NOTES D'UTILISATION
# ============================================================================
# 
# üìã Ce DAG s'ex√©cute automatiquement toutes les 6 heures
# 
# ‚ö†Ô∏è  PR√âREQUIS: Le DAG 'initialization_pipeline' doit avoir √©t√© ex√©cut√©
# 
# üîÑ Flux d'ex√©cution:
#    1. V√©rification de l'initialisation
#    2. Si OK: Mise √† jour des 6h pass√©es (m√©t√©o + √©nergie + batteries r√©elles)
#    3. Puis: Pr√©dictions pour les 7 jours futurs (m√©t√©o + √©nergie + batteries)
#    4. Si KO: Le DAG s'arr√™te imm√©diatement
# 
# üìä Tables mises √† jour:
#    - weather_forecast_hourly (backfill 6h + forecast 7j)
#    - energy_consumption_hourly (backfill 6h)
#    - predicted_energy_consumption (forecast 7j)
#    - predicted_solar_production (forecast 7j)
#    - battery_state (backfill 6h avec is_predicted=FALSE + forecast 7j avec is_predicted=TRUE)
#
# üîß Configuration requise:
#    Variables d'environnement √† d√©finir:
#    - GAUSSDB_HOST ou POSTGRES_HOST (nom du service PostgreSQL)
#    - GAUSSDB_PORT (par d√©faut: 5432)
#    - GAUSSDB_DB_SILVER (par d√©faut: silver)
#    - GAUSSDB_USER (par d√©faut: postgres)
#    - GAUSSDB_PASSWORD (par d√©faut: postgres)
# 
# ============================================================================