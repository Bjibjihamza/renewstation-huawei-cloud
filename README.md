# ğŸ“Š Pipeline de DonnÃ©es - RenewStation

## ğŸ¯ Vue d'ensemble

Le projet RenewStation est une plateforme qui gÃ¨re la collecte, la gÃ©nÃ©ration, et la mise Ã  jour des donnÃ©es mÃ©tÃ©orologiques et Ã©nergÃ©tiques. Ce pipeline automatisÃ© rÃ©cupÃ¨re les donnÃ©es de consommation d'Ã©nergie et de prÃ©visions mÃ©tÃ©orologiques en temps rÃ©el, et utilise des algorithmes pour prÃ©dire la production Ã©nergÃ©tique et gÃ©rer les batteries associÃ©es.

## ğŸ› ï¸ Architecture du Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ARCHITECTURE DU PIPELINE                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“… 1/1/2024 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Aujourd'hui â”€â”€â–º +6h
    â”‚                                            â”‚            â”‚
    â–¼                                            â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HISTORIQUE (donnÃ©es rÃ©elles)    â”‚    â”‚   NOW    â”‚  â”‚ FORECAST â”‚
â”‚  - MÃ©tÃ©o: API Archive            â”‚    â”‚          â”‚  â”‚ (6h)     â”‚
â”‚  - Ã‰nergie: SynthÃ©tique corrÃ©lÃ©  â”‚    â”‚          â”‚  â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â–²            â”‚
                                              â”‚            â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           Backfill auto
                                        (prÃ©visions â†’ rÃ©el)
```

## ğŸ“‚ Structure du Projet

```
renewstation-huawei-cloud/
â”œâ”€â”€ dags/                             # DAGs Airflow pour orchestrer les pipelines
â”‚   â”œâ”€â”€ weather_energy_dag.py          # DAG pour la mÃ©tÃ©o et la consommation Ã©nergÃ©tique
â”‚   â””â”€â”€ initialization_pipeline.py    # Pipeline d'initialisation
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ pipeline/
â”‚       â”œâ”€â”€ generator/                 # GÃ©nÃ©ration des donnÃ©es mÃ©tÃ©o et Ã©nergÃ©tiques
â”‚       â”‚   â”œâ”€â”€ weather_forecasting.py  # Historique et prÃ©visions mÃ©tÃ©o
â”‚       â”‚   â”œâ”€â”€ energy_cons_generator.py # GÃ©nÃ©ration de la consommation Ã©nergÃ©tique
â”‚       â”‚   â””â”€â”€ generate_energy_6h_forecast.py # PrÃ©visions Ã©nergÃ©tiques 6h
â”‚       â””â”€â”€ load/                      # Chargement dans la base de donnÃ©es
â”‚           â”œâ”€â”€ weather_loader.py      # UPSERT des donnÃ©es mÃ©tÃ©o
â”‚           â””â”€â”€ energy_loader.py       # UPSERT des donnÃ©es Ã©nergÃ©tiques
â”‚
â”œâ”€â”€ databases/                        # SchÃ©mas SQL pour les donnÃ©es (bronze, silver, gold)
â”‚   â”œâ”€â”€ bronze.sql                    # SchÃ©ma des donnÃ©es brutes
â”‚   â”œâ”€â”€ silver.sql                    # SchÃ©ma des tables principales
â”‚   â””â”€â”€ gold.sql                      # SchÃ©ma des agrÃ©gations futures
â”‚
â”œâ”€â”€ data/                             # Fichiers de donnÃ©es (CSV, logs)
â”‚   â””â”€â”€ energy_consumption.csv        # Export des donnÃ©es Ã©nergÃ©tiques
â”‚
â”œâ”€â”€ frontend/                         # Code Frontend React
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/               # Composants UI de l'application
â”‚   â”‚   â”œâ”€â”€ Pages/                    # Pages principales (Dashboard, Battery, etc.)
â”‚   â”‚   â””â”€â”€ App.jsx                   # Point d'entrÃ©e de l'application
â”‚   â”œâ”€â”€ public/                       # Fichiers publics (index.html, etc.)
â”‚   â””â”€â”€ Dockerfile                    # Dockerfile pour le Frontend
â”‚
â”œâ”€â”€ api/                              # Backend API (Node.js)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ config/                   # Configuration API
â”‚   â”‚   â”œâ”€â”€ controllers/              # ContrÃ´leurs d'API
â”‚   â”‚   â””â”€â”€ routes/                   # Routes API
â”‚   â”œâ”€â”€ Dockerfile                    # Dockerfile pour l'API
â”‚   â””â”€â”€ package.json                  # DÃ©pendances du Backend
â”‚
â”œâ”€â”€ logs/                             # Logs Airflow
â”œâ”€â”€ notebooks/                        # Jupyter Notebooks pour l'analyse
â”œâ”€â”€ .gitignore                        # Fichiers Ã  ignorer dans Git
â”œâ”€â”€ .env                               # Variables d'environnement
â”œâ”€â”€ docker-compose.yml                # Configuration Docker Compose
â””â”€â”€ README.md                         # Ce fichier README
```

## ğŸš€ Installation et DÃ©marrage

### 1ï¸âƒ£ Cloner le Projet

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/your-repo/renewstation-huawei-cloud.git
cd renewstation-huawei-cloud
```

### 2ï¸âƒ£ Configurer les Variables d'Environnement

Copiez le fichier `.env.example` et renommez-le en `.env`. Ensuite, modifiez les paramÃ¨tres de connexion Ã  la base de donnÃ©es PostgreSQL.

```env
GAUSSDB_HOST=postgres
GAUSSDB_PORT=5432
GAUSSDB_DB_SILVER=silver
GAUSSDB_USER=postgres
GAUSSDB_PASSWORD=your_secure_password
GAUSSDB_SSLMODE=disable
```

### 3ï¸âƒ£ Lancer les Services Docker

```bash
# Lancer les conteneurs Docker
docker-compose up -d --build
# VÃ©rifier que les services sont actifs
docker ps
# Vous devriez voir: postgres, airflow-webserver, airflow-scheduler
```

### 4ï¸âƒ£ Initialiser la Base de DonnÃ©es

```bash
# Se connecter au conteneur PostgreSQL
docker exec -it renewstation-postgres psql -U postgres

# CrÃ©er la base de donnÃ©es Silver
CREATE DATABASE silver;

# Se connecter Ã  la base Silver
\c silver

# ExÃ©cuter le script de crÃ©ation des tables
\i /path/to/databases/silver.sql
```

### 5ï¸âƒ£ AccÃ©der Ã  l'Interface Airflow

Une fois que les services sont en cours d'exÃ©cution, vous pouvez accÃ©der Ã  l'interface d'Airflow via :

- **URL** : http://localhost:8080
- **Utilisateur** : airflow
- **Mot de passe** : airflow

## âš™ï¸ Utilisation du Pipeline

### ğŸ¯ PremiÃ¨re ExÃ©cution (Initial Load)

1. **Activer le DAG**  
   Dans l'interface Airflow :  
   - Allez dans **DAGs**  
   - Trouvez **unified_weather_energy_pipeline**  
   - Activez le toggle (bouton ON/OFF)

2. **DÃ©clencher le DAG Manuellement**  
   - Cliquez sur le bouton â–¶ï¸ **Trigger DAG**  
   - Le pipeline dÃ©tectera automatiquement qu'il s'agit de la premiÃ¨re exÃ©cution  
   - **DurÃ©e estimÃ©e** : 45-60 minutes

3. **Ã‰tapes exÃ©cutÃ©es (PremiÃ¨re ExÃ©cution)**

   ```
   check_initialization_mode
     â””â”€â–º initial_load
          â”œâ”€â–º initial_weather_history       (~10-20 min)
          â”œâ”€â–º initial_energy_history        (~20-30 min)
          â”œâ”€â–º initial_weather_forecast_6h   (~1-2 min)
          â”œâ”€â–º initial_energy_forecast_6h    (~2-3 min)
          â””â”€â–º mark_system_initialized       (~1 sec)
   ```

4. **VÃ©rification du Chargement**

   ```sql
   -- VÃ©rifier les donnÃ©es mÃ©tÃ©o historiques
   SELECT COUNT(*) as total_heures, COUNT(DISTINCT DATE(forecast_timestamp)) as total_jours
   FROM weather_forecast_hourly;

   -- VÃ©rifier la consommation d'Ã©nergie
   SELECT building, COUNT(*) as heures, ROUND(AVG(use_kw), 2) as consommation_moyenne_kw
   FROM energy_consumption_hourly
   GROUP BY building;
   ```

### ğŸ”„ ExÃ©cutions Automatiques (Updates 6h)

AprÃ¨s la premiÃ¨re exÃ©cution, le DAG s'exÃ©cute automatiquement toutes les 6 heures.  
**Schedule** : `0 */6 * * *`  

**Ã‰tapes exÃ©cutÃ©es** :

```
check_initialization_mode
  â””â”€â–º regular_update
       â”œâ”€â–º regular_weather_update_6h
       â””â”€â–º regular_energy_update_6h
```

**DurÃ©e totale update** : ~2-3 minutes

## ğŸ—ï¸ Architecture DÃ©taillÃ©e

### ğŸ“Š Tables de DonnÃ©es

1. **weather_forecast_hourly (PrÃ©visions MÃ©tÃ©o)**  
   DonnÃ©es de prÃ©visions mÃ©tÃ©o Ã  l'heure avec des informations telles que la tempÃ©rature, l'humiditÃ©, la radiation solaire, etc.

2. **energy_consumption_hourly (Consommation d'Ã‰nergie)**  
   DonnÃ©es sur la consommation Ã©nergÃ©tique horaire par bÃ¢timent avec des informations telles que la tempÃ©rature extÃ©rieure, l'Ã©clairage, l'HVAC, etc.

3. **Solar and Battery Data**  
   Tables pour stocker la production d'Ã©nergie solaire et l'Ã©tat de la batterie avec des prÃ©visions et des donnÃ©es rÃ©elles.

### Variables d'Environnement (Fichier `.env`)

```env
# Variables de connexion Ã  la base de donnÃ©es
GAUSSDB_HOST=postgres
GAUSSDB_PORT=5432
GAUSSDB_USER=postgres
GAUSSDB_PASSWORD=your_secure_password
GAUSSDB_DB_SILVER=silver
GAUSSDB_SSLMODE=disable
```

## ğŸ§° Monitoring et VÃ©rification

### Logs Airflow

- **Localisation des logs** : `/logs/`
- **Commande pour afficher les logs en temps rÃ©el** :

  ```bash
  docker logs -f renewstation-airflow-scheduler
  ```