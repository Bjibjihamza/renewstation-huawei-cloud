# RenewStation ‚Äì Plateforme IA de Pr√©diction √ânerg√©tique

**Pr√©cision ¬±149 Watts ¬∑ 17 B√¢timents ¬∑ 7 Jours d'Avance**

---

## üéØ Vue d'Ensemble

RenewStation est une plateforme compl√®te de gestion et pr√©diction √©nerg√©tique utilisant l'Intelligence Artificielle pour anticiper la consommation √©lectrique de 17 b√¢timents avec une pr√©cision exceptionnelle de ¬±149 Watts (0.149 kW).

### üí° Proposition de Valeur

> ¬´ Notre IA pr√©dit votre consommation √©lectrique heure par heure, 7 jours √† l'avance, avec une erreur moyenne de seulement 149 Watts ‚Äî l'√©quivalent d'une ampoule LED. ¬ª

---

## üìä M√©triques de Performance

| M√©trique | Valeur | Description |
|----------|--------|-------------|
| **MAE** | 0.149 kW | Erreur Absolue Moyenne |
| **RMSE** | 0.285 kW | Racine de l'Erreur Quadratique Moyenne |
| **R¬≤** | 0.9980 | Coefficient de D√©termination (99.8%) |
| **Pr√©cision R√©elle** | 73.0% | Pr√©dictions dans la marge ¬±0.149 kW |
| **B√¢timents** | 17 | Couverture totale |
| **Horizon** | 168h | 7 jours (pr√©dictions horaires) |
| **Donn√©es d'Entra√Ænement** | 278 647 | Points de donn√©es r√©elles |

---

## üèóÔ∏è Architecture Compl√®te

### Stack Technologique

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     FRONTEND (React)                        ‚îÇ
‚îÇ              Dashboard Visualisation Temps R√©el             ‚îÇ
‚îÇ                    Port 80 (Nginx)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚îú‚îÄ‚Üí HTTP Requests
                      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  API REST (Node.js/Express)                 ‚îÇ
‚îÇ        Endpoints: Energy, Weather, Solar, Battery           ‚îÇ
‚îÇ                    Port 8000                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚îú‚îÄ‚Üí SQL Queries
                      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              DATABASE (PostgreSQL 16)                       ‚îÇ
‚îÇ           9 Tables Silver Layer (Optimis√©es)                ‚îÇ
‚îÇ                    Port 5432                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚îú‚îÄ‚Üí Read/Write
                      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            AIRFLOW ORCHESTRATION                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇ Scheduler  ‚îÇ  ‚îÇ  Webserver ‚îÇ  ‚îÇ   Worker    ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ  Port 8080 ‚îÇ  ‚îÇ  (UI)      ‚îÇ  ‚îÇ             ‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  DAGs:                                                       ‚îÇ
‚îÇ  ‚Ä¢ daily_prediction_pipeline (00:00 quotidien)              ‚îÇ
‚îÇ  ‚Ä¢ initialization_pipeline (setup initial)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚îú‚îÄ‚Üí ML Training & Inference
                      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  MACHINE LEARNING                           ‚îÇ
‚îÇ              RandomForest Regressor                         ‚îÇ
‚îÇ           Model: energy_predictor.pkl                       ‚îÇ
‚îÇ              (Persist√© & Auto-Updated)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Composants Docker

```yaml
Services:
‚îú‚îÄ‚îÄ postgres          # Base de donn√©es principale
‚îú‚îÄ‚îÄ airflow-init      # Initialisation DB Airflow
‚îú‚îÄ‚îÄ airflow-scheduler # Orchestration DAGs
‚îú‚îÄ‚îÄ airflow-webserver # Interface Airflow UI
‚îú‚îÄ‚îÄ api              # Backend Node.js/Express
‚îî‚îÄ‚îÄ frontend         # Dashboard React/Vite
```

---

## üìÅ Structure Compl√®te du Projet

```
renewstation-huawei-cloud/
‚îÇ
‚îú‚îÄ‚îÄ üìÇ api/                              # Backend REST API
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ database.js             # Configuration PostgreSQL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ solar.controller.js     # Logique m√©tier (18 endpoints)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ solar.routes.js         # Routes Express
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ server.js                   # Point d'entr√©e API
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                      # Image Node.js API
‚îÇ   ‚îú‚îÄ‚îÄ package.json                    # D√©pendances npm
‚îÇ   ‚îî‚îÄ‚îÄ .env.example                    # Template variables
‚îÇ
‚îú‚îÄ‚îÄ üìÇ frontend/                         # Interface Utilisateur
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Pages/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dashboard.jsx           # Page d'accueil
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ EnergyPage.jsx          # Consommation √©nerg√©tique
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SolarPage.jsx           # Production solaire
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Battery.jsx             # √âtat batterie
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ WeatherPage.jsx         # M√©t√©o & pr√©visions
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Overviews.jsx           # Vue d'ensemble
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Overview.tsx            # Composant principal
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BatteryStateSection.tsx # Section batterie
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BatteryVerticalBar.tsx  # Visualisation batterie
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Card.tsx                # Carte g√©n√©rique
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ WeatherMetric.tsx       # M√©triques m√©t√©o
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx                     # Router principal
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.jsx                    # Point d'entr√©e React
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                      # Build multi-stage Vite
‚îÇ   ‚îú‚îÄ‚îÄ nginx.conf                      # Configuration Nginx
‚îÇ   ‚îú‚îÄ‚îÄ package.json                    # D√©pendances React
‚îÇ   ‚îî‚îÄ‚îÄ vite.config.js                  # Config Vite
‚îÇ
‚îú‚îÄ‚îÄ üìÇ dags/                             # Airflow DAGs
‚îÇ   ‚îú‚îÄ‚îÄ daily_prediction_pipeline.py    # Pipeline quotidien 00:00
‚îÇ   ‚îî‚îÄ‚îÄ initialization_pipeline.py      # Setup initial (run once)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ src/                              # Code Pipeline Python
‚îÇ   ‚îú‚îÄ‚îÄ pipeline/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extract/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test.py                 # Extraction donn√©es
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generator/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ energy_cons_generator.py      # G√©n√©ration consommation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ energy_prediction_7d.py       # Pr√©diction ML 7j
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ solar_prediction_7d.py        # Pr√©diction solaire
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ battery_prediction_7d.py      # Pr√©diction batterie
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ weather_forecasting.py        # M√©t√©o actuelle
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ weather_forecast_7d.py        # M√©t√©o 7 jours
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ battery_real_daily.py         # Batterie r√©elle
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ battery_utils.py              # Utilitaires batterie
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ archive_yesterday_sync.py     # Archive J-1
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ load/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ energy_loader.py              # Chargement energy live
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predicted_energy_loader.py    # Chargement ML predictions
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ solar_prediction_loader.py    # Chargement solar pred
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ battery_loader.py             # Chargement batterie
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ weather_loader.py             # Chargement m√©t√©o actuelle
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ weather_loader_7d.py          # Chargement m√©t√©o 7j
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ daily_archive_loader.py       # Archivage quotidien
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ml/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_energy_model.py         # Entra√Ænement mod√®le ML
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transform/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ (transformations si besoin)
‚îÇ   ‚îú‚îÄ‚îÄ helpers/                               # Fonctions utilitaires
‚îÇ   ‚îî‚îÄ‚îÄ init_silver_data.py                   # Init sch√©ma Silver
‚îÇ
‚îú‚îÄ‚îÄ üìÇ models/                           # Mod√®les ML Persist√©s
‚îÇ   ‚îî‚îÄ‚îÄ energy_predictor.pkl            # RandomForest 500 arbres
‚îÇ
‚îú‚îÄ‚îÄ üìÇ notebooks/                        # Jupyter Notebooks
‚îÇ   ‚îú‚îÄ‚îÄ ML_VERIFICATION_FINAL.ipynb     # Validation mod√®le
‚îÇ   ‚îú‚îÄ‚îÄ ML.ipynb                        # Exp√©rimentation ML
‚îÇ   ‚îú‚îÄ‚îÄ battries_verif.ipynb            # Tests batterie
‚îÇ   ‚îú‚îÄ‚îÄ verif_7d.ipynb                  # V√©rification pr√©dictions 7j
‚îÇ   ‚îî‚îÄ‚îÄ prod.ipynb                      # Notebook production
‚îÇ
‚îú‚îÄ‚îÄ üìÇ databases/                        # Scripts SQL
‚îÇ   ‚îî‚îÄ‚îÄ silver.sql                      # Sch√©ma complet Silver Layer
‚îÇ
‚îú‚îÄ‚îÄ üìÇ logs/                             # Logs Airflow
‚îÇ
‚îú‚îÄ‚îÄ üìÑ docker-compose.yml               # Orchestration compl√®te
‚îú‚îÄ‚îÄ üìÑ Dockerfile                       # Image Airflow
‚îú‚îÄ‚îÄ üìÑ requirements.txt                 # D√©pendances Python
‚îú‚îÄ‚îÄ üìÑ .env                             # Variables d'environnement
‚îú‚îÄ‚îÄ üìÑ .gitignore                       # Exclusions Git
‚îî‚îÄ‚îÄ üìÑ README.md                        # Cette documentation
```

---

## üóÑÔ∏è Sch√©ma de Base de Donn√©es (Silver Layer)

### Tables Principales

#### 1. energy_consumption_hourly_archive (Historique Complet)

Stocke toutes les donn√©es historiques de consommation r√©elle.

```sql
CREATE TABLE energy_consumption_hourly_archive (
    id SERIAL PRIMARY KEY,
    building_id INTEGER NOT NULL,
    building_name VARCHAR(255),
    time_ts TIMESTAMP NOT NULL,
    consumed_energy_kwh NUMERIC(10, 3),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Usage:** Base d'entra√Ænement ML, analyses historiques

#### 2. energy_consumption_hourly_live (Donn√©es R√©centes)

Contient les derni√®res heures de consommation r√©elle (fen√™tre glissante).

```sql
CREATE TABLE energy_consumption_hourly_live (
    id SERIAL PRIMARY KEY,
    building_id INTEGER NOT NULL,
    building_name VARCHAR(255),
    time_ts TIMESTAMP NOT NULL,
    consumed_energy_kwh NUMERIC(10, 3),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Usage:** Affichage temps r√©el dashboard, comparaison avec pr√©dictions

#### 3. predicted_energy_consumption_hourly (Pr√©dictions ML)

Pr√©dictions IA pour les 7 prochains jours (168 heures √ó 17 b√¢timents = 2 856 lignes).

```sql
CREATE TABLE predicted_energy_consumption_hourly (
    id SERIAL PRIMARY KEY,
    building_id INTEGER NOT NULL,
    building_name VARCHAR(255),
    time_ts TIMESTAMP NOT NULL,
    predicted_energy_kwh NUMERIC(10, 3),
    model_version VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Usage:** Affichage pr√©dictions dashboard, planification √©nerg√©tique

#### 4. weather_forecast_hourly (Pr√©visions M√©t√©o 7j)

Donn√©es m√©t√©o futures depuis Open-Meteo API.

```sql
CREATE TABLE weather_forecast_hourly (
    id SERIAL PRIMARY KEY,
    forecast_timestamp TIMESTAMP NOT NULL,
    temperature_2m NUMERIC(5, 2),
    relative_humidity_2m INTEGER,
    precipitation NUMERIC(5, 2),
    cloud_cover INTEGER,
    wind_speed_10m NUMERIC(5, 2),
    shortwave_radiation NUMERIC(7, 2),
    direct_radiation NUMERIC(7, 2),
    diffuse_radiation NUMERIC(7, 2),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Usage:** Features ML, affichage m√©t√©o dashboard

#### 5. weather_archive_hourly (Historique M√©t√©o)

Archive des pr√©visions m√©t√©o pass√©es.

```sql
CREATE TABLE weather_archive_hourly (
    -- M√™me structure que weather_forecast_hourly
);
```

#### 6. predicted_solar_production (Production Solaire Pr√©dite)

Pr√©dictions de production solaire sur 7 jours.

```sql
CREATE TABLE predicted_solar_production (
    timestamp TIMESTAMP PRIMARY KEY,
    predicted_solar_kwh NUMERIC(10, 3),
    shortwave_radiation NUMERIC(7, 2),
    direct_radiation NUMERIC(7, 2),
    diffuse_radiation NUMERIC(7, 2),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Usage:** Planification production renouvelable

#### 7. solar_production_archive (Production Solaire R√©elle)

Historique de la production solaire r√©elle.

```sql
CREATE TABLE solar_production_archive (
    id SERIAL PRIMARY KEY,
    timestamp TIMESTAMP NOT NULL,
    actual_solar_kwh NUMERIC(10, 3),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### 8. battery_state_real (√âtat Batterie R√©el)

√âtat de charge r√©el des batteries (J-1).

```sql
CREATE TABLE battery_state_real (
    id SERIAL PRIMARY KEY,
    timestamp TIMESTAMP NOT NULL,
    state_of_charge_percent NUMERIC(5, 2),
    charge_kwh NUMERIC(10, 3),
    discharge_kwh NUMERIC(10, 3),
    net_battery_kwh NUMERIC(10, 3),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### 9. battery_state_predicted (√âtat Batterie Pr√©dit)

Pr√©dictions de l'√©tat de charge sur 7 jours.

```sql
CREATE TABLE battery_state_predicted (
    id SERIAL PRIMARY KEY,
    timestamp TIMESTAMP NOT NULL,
    predicted_soc_percent NUMERIC(5, 2),
    predicted_charge_kwh NUMERIC(10, 3),
    predicted_discharge_kwh NUMERIC(10, 3),
    predicted_net_battery_kwh NUMERIC(10, 3),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

## ü§ñ Machine Learning - D√©tails Techniques

### Mod√®le: RandomForest Regressor

**Fichier:** `src/pipeline/ml/train_energy_model.py`

#### Configuration

```python
RandomForestRegressor(
    n_estimators=500,      # 500 arbres de d√©cision
    max_depth=20,          # Profondeur maximale
    min_samples_split=5,   # Minimum √©chantillons pour split
    min_samples_leaf=2,    # Minimum √©chantillons par feuille
    random_state=42,       # Reproductibilit√©
    n_jobs=-1              # Parall√©lisation
)
```

#### Features Utilis√©es

```python
features = [
    'hour',                    # Heure de la journ√©e (0-23)
    'day_of_week',            # Jour de la semaine (0-6)
    'month',                  # Mois (1-12)
    'is_weekend',             # Weekend (0/1)
    'building_id',            # ID unique b√¢timent
    'temperature_2m',         # Temp√©rature ¬∞C
    'relative_humidity_2m',   # Humidit√© %
    'precipitation',          # Pr√©cipitations mm
    'cloud_cover',           # Couverture nuageuse %
    'wind_speed_10m',        # Vitesse vent km/h
    'shortwave_radiation',   # Radiation W/m¬≤
]
```

#### M√©triques de Performance

```
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
MOD√àLE R√â-ENTRA√éN√â - PR√âCISION EXTR√äME D√âTECT√âE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

MAE                    : 0.149 kW
RMSE                   : 0.285 kW
R¬≤                     : 0.9980

PR√âCISION R√âELLE       : 73.0% des pr√©dictions dans ¬±0.149 kW
                       ‚Üí Erreur moyenne de seulement 149 Watts !

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Mod√®le √©cras√© et mis √† jour :
 ‚Üí /opt/airflow/models/energy_predictor.pkl
 ‚Üí models/energy_predictor.pkl
```

#### Entra√Ænement

Le mod√®le est entra√Æn√© sur **278 647 points de donn√©es r√©elles** couvrant:

- 17 b√¢timents diff√©rents
- 10+ jours d'historique
- Toutes les heures de la journ√©e
- Conditions m√©t√©o vari√©es

#### R√©-entra√Ænement

```bash
# Commande manuelle
docker exec -it renewstation-airflow-scheduler \
  python -m src.pipeline.ml.train_energy_model

# Automatique via DAG (√† programmer si besoin)
```

Le fichier `models/energy_predictor.pkl` est **√©cras√© automatiquement** √† chaque entra√Ænement.

---

## üîå API REST - Documentation Compl√®te

### Base URL

```
http://localhost:8000/api/solar
```

### Endpoints Disponibles

#### üè† Energy Consumption

**1. GET /energy-consumption-archive**

R√©cup√®re l'historique complet de consommation.

Query Parameters:
- `page` (integer, default: 1)
- `limit` (integer, default: 100, max: 1000)

Response:
```json
{
  "count": 278647,
  "results": [
    {
      "id": 1,
      "building_id": 1,
      "building_name": "Hospital",
      "time_ts": "2025-11-13T10:00:00Z",
      "consumed_energy_kwh": 2.456,
      "created_at": "2025-11-13T10:05:00Z"
    }
  ],
  "page": 1,
  "totalPages": 2787
}
```

**2. GET /energy-consumption-archive/:id**

R√©cup√®re un enregistrement sp√©cifique.

**3. GET /energy-consumption-live**

R√©cup√®re les donn√©es r√©centes (fen√™tre glissante).

**4. GET /energy-consumption-live/:id**

R√©cup√®re un enregistrement live sp√©cifique.

#### üå§Ô∏è Weather Data

**5. GET /weather-forecast-hourly**

Pr√©visions m√©t√©o 7 jours.

Response:
```json
{
  "count": 168,
  "results": [
    {
      "id": 1,
      "forecast_timestamp": "2025-11-14T00:00:00Z",
      "temperature_2m": 18.5,
      "relative_humidity_2m": 65,
      "precipitation": 0.2,
      "cloud_cover": 40,
      "wind_speed_10m": 12.3,
      "shortwave_radiation": 450.2,
      "direct_radiation": 320.5,
      "diffuse_radiation": 129.7
    }
  ],
  "page": 1,
  "totalPages": 2
}
```

**6. GET /weather-forecast-hourly/:timestamp**

Pr√©vision pour un timestamp sp√©cifique.

**7. GET /weather-archive-hourly**

Historique m√©t√©o.

**8. GET /weather-archive-hourly/:timestamp**

Archive m√©t√©o pour un timestamp.

#### ‚ö° Predicted Energy (ML)

**9. GET /predicted-energy-consumption**

Pr√©dictions IA 7 jours (2 856 pr√©dictions).

Response:
```json
{
  "count": 2856,
  "results": [
    {
      "id": 1,
      "building_id": 1,
      "building_name": "Hospital",
      "time_ts": "2025-11-14T00:00:00Z",
      "predicted_energy_kwh": 2.398,
      "model_version": "energy_predictor.pkl",
      "created_at": "2025-11-13T00:01:00Z"
    }
  ],
  "page": 1,
  "totalPages": 29
}
```

**10. GET /predicted-energy-consumption/:id**

Pr√©diction sp√©cifique par ID.

#### ‚òÄÔ∏è Solar Production

**11. GET /solar-production-archive**

Production solaire historique.

**12. GET /solar-production-archive/:id**

Production pour un ID sp√©cifique.

**13. GET /predicted-solar-production**

Pr√©dictions solaires 7 jours.

Response:
```json
{
  "count": 168,
  "results": [
    {
      "timestamp": "2025-11-14T08:00:00Z",
      "predicted_solar_kwh": 12.456,
      "shortwave_radiation": 780.5,
      "direct_radiation": 620.3,
      "diffuse_radiation": 160.2
    }
  ]
}
```

**14. GET /predicted-solar-production/:timestamp**

Pr√©diction solaire pour un timestamp.

#### üîã Battery State

**15. GET /battery-state-real**

√âtat r√©el batterie (historique).

Response:
```json
{
  "count": 240,
  "results": [
    {
      "id": 1,
      "timestamp": "2025-11-13T23:00:00Z",
      "state_of_charge_percent": 85.5,
      "charge_kwh": 15.2,
      "discharge_kwh": 8.3,
      "net_battery_kwh": 6.9
    }
  ]
}
```

**16. GET /battery-state-real/:id**

√âtat r√©el pour un ID sp√©cifique.

**17. GET /battery-state-predicted**

Pr√©dictions batterie 7 jours.

**18. GET /battery-state-predicted/:id**

Pr√©diction batterie pour un ID.

**19. GET /battery-state?source=all|real|predicted**

Endpoint unifi√© pour le dashboard.

Query Parameters:
- `source`: all (default), real, predicted

#### üìä Summary

**20. GET /summary**

Vue d'ensemble de toutes les tables.

Response:
```json
{
  "tables": {
    "energy_consumption_hourly_archive": 278647,
    "energy_consumption_hourly_live": 240,
    "weather_forecast_hourly": 168,
    "weather_archive_hourly": 1200,
    "predicted_energy_consumption_hourly": 2856,
    "solar_production_archive": 500,
    "predicted_solar_production": 168,
    "battery_state_real": 240,
    "battery_state_predicted": 168
  },
  "timestamp": "2025-11-14T00:00:00Z"
}
```

#### üè• Health Check

**21. GET /health**

V√©rification sant√© API.

Response:
```json
{
  "status": "OK",
  "uptime": 3600.5,
  "timestamp": "2025-11-14T00:00:00Z"
}
```

---

## üé® Frontend Dashboard - React/Vite

### Technologies

- **React 18** - Framework UI
- **Vite** - Build tool ultra-rapide
- **Tailwind CSS** - Styling utility-first
- **Recharts** - Visualisations graphiques
- **Lucide React** - Ic√¥nes modernes
- **Nginx** - Serveur web production

### Pages Disponibles

#### 1. Dashboard (/)
Vue d'ensemble g√©n√©rale avec KPIs principaux.

#### 2. Energy Page (/energy)
- Graphiques consommation r√©elle vs pr√©dite
- Comparaison 17 b√¢timents
- Ligne rouge "AUJOURD'HUI"
- 10 jours pass√©s (bleu) + 7 jours futurs (orange)

#### 3. Solar Page (/solar)
- Production solaire historique
- Pr√©dictions 7 jours
- Corr√©lation avec radiation solaire

#### 4. Battery Page (/battery)
- √âtat de charge (SOC %)
- Charge/D√©charge (kWh)
- Pr√©dictions 7 jours
- Visualisation barre verticale

#### 5. Weather Page (/weather)
- Pr√©visions 7 jours
- Temp√©rature, humidit√©, pr√©cipitations
- Radiation solaire (shortwave, direct, diffuse)

#### 6. Overviews (/overviews)
Vue consolid√©e multi-m√©triques.

### Configuration API

Fichier: `frontend/.env` (ou variables d'environnement Docker)

```bash
VITE_API_URL=http://localhost:8000
```

Le frontend appelle automatiquement:

```javascript
fetch(`${import.meta.env.VITE_API_URL}/api/solar/predicted-energy-consumption`)
```

---

## üöÄ D√©marrage Complet - Guide Pas √† Pas

### Pr√©requis

- Docker >= 24.0
- Docker Compose >= 2.20
- Git
- 8 GB RAM minimum (recommand√© 16 GB)
- 20 GB espace disque

### Installation Depuis Z√©ro

#### √âtape 1: Cloner le Projet

```bash
git clone https://github.com/Bjibjihamza/renewstation-huawei-cloud.git
cd renewstation-huawei-cloud
```

#### √âtape 2: Configuration Variables d'Environnement

```bash
# Cr√©er le fichier .env √† la racine
cat > .env << EOF
# PostgreSQL
GAUSSDB_DB_SILVER=silver
GAUSSDB_USER=postgres
GAUSSDB_PASSWORD=postgres

# Airflow
AIRFLOW__CORE__FERNET_KEY=sAsfiDM_fXGu_TD6n2XM5ZiOaO2ul-1UR4lHx4k6u1k=
EOF
```

```bash
# Cr√©er le fichier api/.env
cat > api/.env << EOF
NODE_ENV=production
DB_HOST=postgres
DB_PORT=5432
DB_NAME=silver
DB_USER=postgres
DB_PASSWORD=postgres
PORT=8000
EOF
```

#### √âtape 3: Lancer la Stack Compl√®te

```bash
# Build & start tous les services
docker compose up -d --build

# V√©rifier les logs
docker compose logs -f
```

**Temps d'attente:** ~2-3 minutes pour l'initialisation compl√®te.

#### √âtape 4: Initialiser le Sch√©ma Silver

```bash
# Attendre que PostgreSQL soit pr√™t
docker exec -it renewstation-postgres pg_isready -U postgres

# Cr√©er les tables
docker exec -i renewstation-postgres psql -U postgres -d silver < databases/silver.sql
```

#### √âtape 5: Charger les Donn√©es Initiales

```bash
# Lancer le DAG d'initialisation (run once)
docker exec -it renewstation-airflow-scheduler \
  airflow dags trigger initialization_pipeline

# Attendre ~5 minutes, puis v√©rifier
docker exec -it renewstation-postgres psql -U postgres -d silver -c \
  "SELECT COUNT(*) FROM energy_consumption_hourly_archive;"
```

**R√©sultat attendu:** ~278 647 lignes

#### √âtape 6: Entra√Æner le Mod√®le ML

```bash
# Entra√Ænement initial (obligatoire)
docker exec -it renewstation-airflow-scheduler \
  python -m src.pipeline.ml.train_energy_model
```

**Output attendu:**
```
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
MOD√àLE R√â-ENTRA√éN√â - PR√âCISION EXTR√äME D√âTECT√âE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
MAE: 0.149 kW | RMSE: 0.285 kW | R¬≤: 0.9980
‚úÖ Mod√®le sauvegard√©: models/energy_predictor.pkl
```

#### √âtape 7: Lancer le Pipeline Quotidien

```bash
# G√©n√®re toutes les pr√©dictions 7 jours
docker exec -it renewstation-airflow-scheduler \
  airflow dags trigger daily_prediction_pipeline

# V√©rifier le chargement des pr√©dictions
docker exec -it renewstation-postgres psql -U postgres -d silver -c \
  "SELECT COUNT(*) FROM predicted_energy_consumption_hourly;"
```

**R√©sultat attendu:** 2 856 pr√©dictions (17 b√¢timents √ó 168 heures)

#### √âtape 8: Acc√©der aux Interfaces

| Service | URL | Credentials |
|---------|-----|-------------|
| **Frontend Dashboard** | http://localhost | ‚Äî |
| **API Swagger (root)** | http://localhost:8000 | ‚Äî |
| **Airflow UI** | http://localhost:8080 | admin / admin |
| **PostgreSQL** | localhost:5432 | postgres / postgres |

### V√©rification de Sant√©

```bash
# Sant√© API
curl http://localhost:8000/health

# Sant√© Frontend
curl http://localhost/health

# Sant√© Airflow
docker exec renewstation-airflow-scheduler airflow jobs check --job-type SchedulerJob

# V√©rification compl√®te base de donn√©es
docker exec -it renewstation-postgres psql -U postgres -d silver -c "
SELECT 
  table_name,
  (SELECT COUNT(*) FROM information_schema.columns WHERE table_name = t.table_name) as columns,
  pg_size_pretty(pg_total_relation_size(quote_ident(table_name))) as size
FROM information_schema.tables t
WHERE table_schema = 'public'
ORDER BY table_name;
"
```

---

## üîÑ Pipelines Airflow - DAGs D√©taill√©s

### 1. initialization_pipeline.py (Run Once)

**Description:** Pipeline d'initialisation pour setup initial des donn√©es.

**Fr√©quence:** Manuelle (une seule fois au d√©marrage)

**Tasks:**
- `check_database_connection` - V√©rifie connexion PostgreSQL
- `create_silver_schema` - Cr√©e les tables si inexistantes
- `generate_historical_energy` - G√©n√®re donn√©es historiques (10 jours)
- `load_historical_energy` - Charge dans energy_consumption_hourly_archive
- `generate_weather_archive` - R√©cup√®re m√©t√©o historique
- `load_weather_archive` - Charge dans weather_archive_hourly
- `verify_initialization` - V√©rifie counts

**Commande:**
```bash
docker exec -it renewstation-airflow-scheduler \
  airflow dags trigger initialization_pipeline
```

**Dur√©e:** ~5-8 minutes

---

### 2. daily_prediction_pipeline.py (Quotidien 00:00)

**Description:** Pipeline principal de pr√©diction, s'ex√©cute chaque jour √† minuit.

**Fr√©quence:** `@daily` (00:00 UTC)

**Tasks (ordre d'ex√©cution):**

#### Phase 1: Archivage (00:00 - 00:05)
```
archive_yesterday_task
  ‚Üì
  Archive les donn√©es J-1 depuis live ‚Üí archive
  Source: energy_consumption_hourly_live
  Destination: energy_consumption_hourly_archive
```

#### Phase 2: G√©n√©ration Donn√©es R√©elles (00:05 - 00:10)
```
generate_energy_consumption_task
  ‚Üì
  G√©n√®re consommation r√©elle pour aujourd'hui (24h)
  Destination: energy_consumption_hourly_live

generate_battery_real_task
  ‚Üì
  Calcule √©tat batterie r√©el (J-1)
  Destination: battery_state_real
```

#### Phase 3: M√©t√©o (00:10 - 00:15)
```
generate_weather_current_task
  ‚Üì
  R√©cup√®re m√©t√©o actuelle Open-Meteo
  Destination: weather_archive_hourly

generate_weather_forecast_7d_task
  ‚Üì
  R√©cup√®re pr√©visions 7 jours
  Destination: weather_forecast_hourly
```

#### Phase 4: Pr√©dictions ML (00:15 - 00:20)
```
generate_energy_prediction_7d_task
  ‚Üì
  Utilise energy_predictor.pkl
  G√©n√®re 2 856 pr√©dictions (17 buildings √ó 168h)
  Destination: predicted_energy_consumption_hourly
```

#### Phase 5: Pr√©dictions Solaire & Batterie (00:20 - 00:25)
```
generate_solar_prediction_7d_task
  ‚Üì
  Pr√©dictions production solaire 7j
  Destination: predicted_solar_production

generate_battery_prediction_7d_task
  ‚Üì
  Pr√©dictions √©tat batterie 7j
  Destination: battery_state_predicted
```

#### Phase 6: Chargement en Base (00:25 - 00:30)
```
load_energy_consumption_task ‚Üí charge energy live
load_predicted_energy_task ‚Üí charge predictions ML
load_solar_prediction_task ‚Üí charge solar predictions
load_battery_real_task ‚Üí charge battery real
load_battery_predicted_task ‚Üí charge battery predictions
load_weather_current_task ‚Üí charge weather archive
load_weather_forecast_7d_task ‚Üí charge weather forecast
```

#### Phase 7: V√©rification Finale
```
verify_predictions_task
  ‚Üì
  V√©rifie counts et int√©grit√© donn√©es
  Log final dans Airflow UI
```

**Visualisation DAG:**
```
archive_yesterday
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       ‚îÇ            ‚îÇ            ‚îÇ
energy  battery   weather      weather
gen     real_gen  current_gen  forecast_7d
‚îÇ       ‚îÇ            ‚îÇ            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
energy_prediction_7d (ML)
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       ‚îÇ            ‚îÇ
solar   battery     
pred    pred        
‚îÇ       ‚îÇ           
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
load_all_data_parallel
    ‚Üì
verify_predictions
```

**Logs en temps r√©el:**
```bash
# Suivre l'ex√©cution du DAG
docker exec -it renewstation-airflow-scheduler \
  airflow dags list-runs -d daily_prediction_pipeline --state running

# Logs d√©taill√©s d'une task
docker exec -it renewstation-airflow-scheduler \
  airflow tasks logs daily_prediction_pipeline generate_energy_prediction_7d_task 2025-11-14
```

---

## üìä Monitoring & Observabilit√©

### M√©triques Cl√©s √† Surveiller

#### 1. Performance ML

```sql
-- V√©rifier pr√©cision des pr√©dictions (comparaison r√©el vs pr√©dit)
SELECT 
  DATE_TRUNC('day', a.time_ts) as day,
  AVG(ABS(a.consumed_energy_kwh - p.predicted_energy_kwh)) as mae,
  COUNT(*) as predictions_count
FROM energy_consumption_hourly_archive a
JOIN predicted_energy_consumption_hourly p 
  ON a.building_id = p.building_id 
  AND a.time_ts = p.time_ts
WHERE a.time_ts >= NOW() - INTERVAL '7 days'
GROUP BY DATE_TRUNC('day', a.time_ts)
ORDER BY day DESC;
```

#### 2. √âtat des Donn√©es

```sql
-- Dashboard counts
SELECT 
  'Archive Energy' as table_name, 
  COUNT(*) as count,
  MAX(time_ts) as latest_timestamp
FROM energy_consumption_hourly_archive
UNION ALL
SELECT 
  'Live Energy', 
  COUNT(*),
  MAX(time_ts)
FROM energy_consumption_hourly_live
UNION ALL
SELECT 
  'Predicted Energy', 
  COUNT(*),
  MAX(time_ts)
FROM predicted_energy_consumption_hourly
UNION ALL
SELECT 
  'Weather Forecast', 
  COUNT(*),
  MAX(forecast_timestamp)
FROM weather_forecast_hourly
UNION ALL
SELECT 
  'Solar Predicted', 
  COUNT(*),
  MAX(timestamp)
FROM predicted_solar_production
UNION ALL
SELECT 
  'Battery Real', 
  COUNT(*),
  MAX(timestamp)
FROM battery_state_real
UNION ALL
SELECT 
  'Battery Predicted', 
  COUNT(*),
  MAX(timestamp)
FROM battery_state_predicted;
```

#### 3. Performance API

```bash
# Temps de r√©ponse endpoint predictions
time curl -s http://localhost:8000/api/solar/predicted-energy-consumption?limit=100 > /dev/null

# Nombre de requ√™tes par minute (logs Nginx)
docker exec renewstation-frontend tail -f /var/log/nginx/access.log | \
  awk '{print $4}' | cut -d: -f2 | uniq -c
```

#### 4. Sant√© Services

```bash
# Script de monitoring complet
cat > monitor.sh << 'EOF'
#!/bin/bash
echo "=== RenewStation Health Check ==="
echo ""
echo "1. Docker Services:"
docker compose ps
echo ""
echo "2. API Health:"
curl -s http://localhost:8000/health | jq
echo ""
echo "3. Frontend Health:"
curl -s http://localhost/health
echo ""
echo "4. Database Connection:"
docker exec renewstation-postgres pg_isready -U postgres
echo ""
echo "5. Airflow DAGs Status:"
docker exec renewstation-airflow-scheduler airflow dags list | grep daily_prediction_pipeline
echo ""
echo "6. Recent Predictions Count:"
docker exec renewstation-postgres psql -U postgres -d silver -t -c \
  "SELECT COUNT(*) FROM predicted_energy_consumption_hourly WHERE created_at >= NOW() - INTERVAL '1 day';"
echo ""
echo "7. Model File:"
ls -lh models/energy_predictor.pkl
EOF

chmod +x monitor.sh
./monitor.sh
```

### Alertes Recommand√©es

**Alertes Critiques:**
- DAG `daily_prediction_pipeline` failed
- PostgreSQL down
- API returning 500 errors
- Model file `energy_predictor.pkl` missing

**Alertes Warning:**
- Predictions count < 2800 (attendu: 2856)
- MAE > 0.200 kW (d√©gradation mod√®le)
- Airflow task retry > 3
- Disk usage > 80%

---

## üõ†Ô∏è Maintenance & Op√©rations

### T√¢ches Quotidiennes

#### 1. V√©rifier Ex√©cution DAG

```bash
# Check si le DAG s'est bien ex√©cut√© cette nuit
docker exec renewstation-airflow-scheduler \
  airflow dags list-runs -d daily_prediction_pipeline --state success | head -5
```

#### 2. V√©rifier Fra√Æcheur Donn√©es

```sql
-- Les pr√©dictions doivent √™tre < 24h
SELECT 
  MAX(created_at) as latest_prediction,
  NOW() - MAX(created_at) as age
FROM predicted_energy_consumption_hourly;
```

**Attendu:** age < 24 hours

### T√¢ches Hebdomadaires

#### 1. R√©-entra√Æner le Mod√®le ML

```bash
# Tous les lundis par exemple
docker exec -it renewstation-airflow-scheduler \
  python -m src.pipeline.ml.train_energy_model

# V√©rifier nouvelle MAE
# Si MAE < 0.149 kW ‚Üí excellent
# Si MAE > 0.200 kW ‚Üí investiguer
```

#### 2. Nettoyer Logs Airflow

```bash
# Garder seulement 30 jours de logs
docker exec renewstation-airflow-scheduler \
  find /opt/airflow/logs -type f -mtime +30 -delete
```

#### 3. Vacuum PostgreSQL

```sql
-- Optimiser les tables
VACUUM ANALYZE energy_consumption_hourly_archive;
VACUUM ANALYZE predicted_energy_consumption_hourly;
VACUUM ANALYZE weather_forecast_hourly;
```

### T√¢ches Mensuelles

#### 1. Backup Base de Donn√©es

```bash
# Backup complet
docker exec renewstation-postgres pg_dump -U postgres silver | \
  gzip > backup_silver_$(date +%Y%m%d).sql.gz

# Restauration
gunzip < backup_silver_20251114.sql.gz | \
  docker exec -i renewstation-postgres psql -U postgres silver
```

#### 2. Analyser Croissance Donn√©es

```sql
SELECT 
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,
  pg_total_relation_size(schemaname||'.'||tablename) AS size_bytes
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY size_bytes DESC;
```

#### 3. Audit S√©curit√©

```bash
# V√©rifier versions Docker images
docker images | grep renewstation

# Scanner vuln√©rabilit√©s
docker scout cves renewstation-api
docker scout cves renewstation-frontend
```

### Proc√©dures d'Urgence

#### Situation 1: API Down

```bash
# 1. Check logs
docker logs renewstation-api --tail 100

# 2. Restart service
docker compose restart api

# 3. Verify health
curl http://localhost:8000/health
```

#### Situation 2: Pr√©dictions Manquantes

```bash
# 1. V√©rifier si le mod√®le existe
ls -lh models/energy_predictor.pkl

# 2. Re-train si manquant
docker exec -it renewstation-airflow-scheduler \
  python -m src.pipeline.ml.train_energy_model

# 3. Re-run DAG
docker exec -it renewstation-airflow-scheduler \
  airflow dags trigger daily_prediction_pipeline
```

#### Situation 3: PostgreSQL Corruption

```bash
# 1. Stop services
docker compose stop

# 2. Backup volumes
docker run --rm -v renewstation-huawei-cloud_postgres_data:/data \
  -v $(pwd):/backup alpine tar czf /backup/postgres_backup.tar.gz /data

# 3. Restore ou recr√©er
docker compose down -v
docker compose up -d
# Re-run initialization_pipeline
```

#### Situation 4: Disque Plein

```bash
# 1. Identifier gros fichiers
du -h --max-depth=2 | sort -hr | head -20

# 2. Nettoyer logs
rm -rf logs/dag_processor_manager/*
rm -rf logs/scheduler/*

# 3. Nettoyer Docker
docker system prune -a --volumes
```

---

## üö¢ D√©ploiement Production Huawei Cloud

### Architecture Cloud Recommand√©e

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Huawei Cloud ECS                         ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              ELB (Load Balancer)                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              Port 80/443 (SSL)                       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ               ‚îÇ                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         Frontend (Nginx + React)                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         Container: renewstation-frontend             ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ               ‚îÇ                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         API Backend (Node.js)                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         Container: renewstation-api                  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ               ‚îÇ                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ    PostgreSQL (RDS ou Container)                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    Database: silver                                  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ               ‚îÇ                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         Airflow (Scheduler + Webserver)              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ML Pipeline Orchestration                    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         OBS (Object Storage)                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         - ML Models                                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         - Backups                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         - Logs Archive                               ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Configuration Serveur ECS

**Sp√©cifications Recommand√©es:**
- Type: General Purpose (s6)
- vCPUs: 4
- RAM: 16 GB
- Disque: 100 GB SSD
- OS: Ubuntu 22.04 LTS
- R√©gion: Proche utilisateurs (ex: Europe-Paris)

### √âtapes de D√©ploiement

#### 1. Pr√©paration Serveur

```bash
# Connexion SSH
ssh root@<ECS_PUBLIC_IP>

# Mise √† jour syst√®me
apt update && apt upgrade -y

# Installation Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

# Installation Docker Compose
apt install docker-compose-plugin -y

# V√©rification
docker --version
docker compose version
```

#### 2. Configuration Firewall & S√©curit√©

```bash
# Installer UFW
apt install ufw -y

# R√®gles firewall
ufw allow 22/tcp    # SSH
ufw allow 80/tcp    # HTTP
ufw allow 443/tcp   # HTTPS
ufw enable

# D√©sactiver acc√®s direct PostgreSQL/Airflow depuis internet
# (acc√®s uniquement via localhost)
```

**Configuration Huawei Security Group:**
- Inbound: 22, 80, 443
- Outbound: All
- Ne PAS ouvrir 5432, 8080, 8000 publiquement

#### 3. Cloner & Configurer Projet

```bash
# Cr√©er utilisateur d√©di√©
useradd -m -s /bin/bash renewstation
usermod -aG docker renewstation
su - renewstation

# Cloner projet
cd /home/renewstation
git clone https://github.com/Bjibjihamza/renewstation-huawei-cloud.git
cd renewstation-huawei-cloud

# Configuration production
cat > .env << EOF
GAUSSDB_DB_SILVER=silver
GAUSSDB_USER=renewstation_user
GAUSSDB_PASSWORD=$(openssl rand -base64 32)
AIRFLOW__CORE__FERNET_KEY=$(python3 -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())")
EOF

# S√©curiser
chmod 600 .env

# API config
cat > api/.env << EOF
NODE_ENV=production
DB_HOST=postgres
DB_PORT=5432
DB_NAME=silver
DB_USER=renewstation_user
DB_PASSWORD=$(grep GAUSSDB_PASSWORD .env | cut -d= -f2)
PORT=8000
EOF
```

#### 4. SSL/TLS avec Let's Encrypt

```bash
# Installer Certbot
apt install certbot python3-certbot-nginx -y

# Obtenir certificat
certbot --nginx -d renewstation.votre-domaine.com

# Auto-renouvellement
systemctl enable certbot.timer
```

**Modifier `frontend/nginx.conf` pour SSL:**

```nginx
server {
    listen 80;
    listen 443 ssl http2;
    server_name renewstation.votre-domaine.com;

    ssl_certificate /etc/letsencrypt/live/renewstation.votre-domaine.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/renewstation.votre-domaine.com/privkey.pem;

    # Redirect HTTP to HTTPS
    if ($scheme = http) {
        return 301 https://$server_name$request_uri;
    }

    # ... reste de la config
}
```

#### 5. D√©marrage Production

```bash
# Build & start
docker compose up -d --build

# Attendre initialisation
sleep 120

# Cr√©er sch√©ma
docker exec -i renewstation-postgres psql -U renewstation_user -d silver < databases/silver.sql

# Initialization pipeline
docker exec renewstation-airflow-scheduler \
  airflow dags trigger initialization_pipeline

# Attendre fin (~8 min)
docker exec renewstation-airflow-scheduler \
  airflow dags list-runs -d initialization_pipeline

# Train mod√®le
docker exec renewstation-airflow-scheduler \
  python -m src.pipeline.ml.train_energy_model

# Premier pipeline quotidien
docker exec renewstation-airflow-scheduler \
  airflow dags trigger daily_prediction_pipeline
```

#### 6. Monitoring Production

**Installer Prometheus + Grafana (optionnel):**

```bash
# Ajouter au docker-compose.yml
# ... prometheus, grafana, node-exporter, postgres-exporter
```

**Setup Logs Centralis√©s:**

```bash
# Logrotate pour logs Docker
cat > /etc/logrotate.d/renewstation << EOF
/home/renewstation/renewstation-huawei-cloud/logs/*.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    notifempty
}
EOF
```

#### 7. Backup Automatis√©

```bash
# Script backup quotidien
cat > /home/renewstation/backup.sh << 'EOF'
#!/bin/bash
BACKUP_DIR="/home/renewstation/backups"
DATE=$(date +%Y%m%d_%H%M%S)

mkdir -p $BACKUP_DIR

# Backup PostgreSQL
docker exec renewstation-postgres pg_dump -U renewstation_user silver | \
  gzip > $BACKUP_DIR/db_$DATE.sql.gz

# Backup ML model
cp renewstation-huawei-cloud/models/energy_predictor.pkl \
  $BACKUP_DIR/model_$DATE.pkl

# Upload vers Huawei OBS (si configur√©)
# obsutil cp $BACKUP_DIR/db_$DATE.sql.gz obs://renewstation-backups/

# Garder seulement 30 derniers backups
ls -t $BACKUP_DIR/db_*.sql.gz | tail -n +31 | xargs rm -f
ls -t $BACKUP_DIR/model_*.pkl | tail -n +31 | xargs rm -f
EOF

chmod +x /home/renewstation/backup.sh

# Cron quotidien 02:00
crontab -e
# Ajouter:
# 0 2 * * * /home/renewstation/backup.sh >> /home/renewstation/backup.log 2>&1
```

#### 8. Systemd Service (auto-restart)

```bash
cat > /etc/systemd/system/renewstation.service << EOF
[Unit]
Description=RenewStation Docker Compose
Requires=docker.service
After=docker.service

[Service]
Type=oneshot
RemainAfterExit=yes
WorkingDirectory=/home/renewstation/renewstation-huawei-cloud
ExecStart=/usr/bin/docker compose up -d
ExecStop=/usr/bin/docker compose down
TimeoutStartSec=0
User=renewstation

[Install]
WantedBy=multi-user.target
EOF

systemctl enable renewstation
systemctl start renewstation
```

---

## üß™ Tests & Validation

### Tests Unitaires API

```bash
# Installer Jest (si pas d√©j√† fait)
cd api
npm install --save-dev jest supertest

# Cr√©er tests
mkdir -p tests
cat > tests/api.test.js << 'EOF'
const request = require('supertest');
const app = require('../src/server');

describe('API Endpoints', () => {
  test('GET /health should return 200', async () => {
    const response = await request(app).get('/health');
    expect(response.statusCode).toBe(200);
    expect(response.body.status).toBe('OK');
  });

  test('GET /api/solar/summary should return counts', async () => {
    const response = await request(app).get('/api/solar/summary');
    expect(response.statusCode).toBe(200);
    expect(response.body.tables).toHaveProperty('predicted_energy_consumption_hourly');
  });
});
EOF

# Run tests
npm test
```

### Tests Integration Pipeline

```bash
# Test complet du pipeline
cat > tests/test_pipeline.sh << 'EOF'
#!/bin/bash
set -e

echo "=== Testing RenewStation Pipeline ==="

# 1. Test database connection
echo "1. Testing database..."
docker exec renewstation-postgres psql -U postgres -d silver -c "SELECT 1;"

# 2. Test data generation
echo "2. Testing energy generation..."
docker exec renewstation-airflow-scheduler \
  python -c "from src.pipeline.generator.energy_cons_generator import generate_energy_consumption; print(len(generate_energy_consumption()))"

# 3. Test ML model
echo "3. Testing ML model..."
docker exec renewstation-airflow-scheduler \
  python -c "import pickle; model=pickle.load(open('/opt/airflow/models/energy_predictor.pkl','rb')); print(type(model))"

# 4. Test API endpoints
echo "4. Testing API..."
curl -f http://localhost:8000/health
curl -f http://localhost:8000/api/solar/summary

# 5. Test frontend
echo "5. Testing frontend..."
curl -f http://localhost/ > /dev/null

echo "‚úÖ All tests passed!"
EOF

chmod +x tests/test_pipeline.sh
./tests/test_pipeline.sh
```

### Validation Pr√©dictions ML

```python
# Notebook: notebooks/ML_VERIFICATION_FINAL.ipynb
import pandas as pd
import psycopg2
import matplotlib.pyplot as plt

# Connect to database
conn = psycopg2.connect(
    host="localhost",
    database="silver",
    user="postgres",
    password="postgres"
)

# Load real vs predicted
query = """
SELECT 
    a.building_name,
    a.time_ts,
    a.consumed_energy_kwh as real,
    p.predicted_energy_kwh as predicted
FROM energy_consumption_hourly_archive a
JOIN predicted_energy_consumption_hourly p 
  ON a.building_id = p.building_id 
  AND a.time_ts = p.time_ts
WHERE a.time_ts >= NOW() - INTERVAL '7 days'
ORDER BY a.building_name, a.time_ts;
"""

df = pd.read_sql(query, conn)
df['error'] = abs(df['real'] - df['predicted'])

# Calculate metrics
mae = df['error'].mean()
rmse = (df['error'] ** 2).mean() ** 0.5

print(f"MAE: {mae:.3f} kW")
print(f"RMSE: {rmse:.3f} kW")

# Plot per building
for building in df['building_name'].unique():
    building_df = df[df['building_name'] == building]
    plt.figure(figsize=(12, 4))
    plt.plot(building_df['time_ts'], building_df['real'], label='Real', color='blue')
    plt.plot(building_df['time_ts'], building_df['predicted'], label='Predicted', color='orange')
    plt.title(f'{building} - Real vs Predicted')
    plt.legend()
    plt.show()
```

---

## üìö Documentation D√©veloppeurs

### Ajouter un Nouveau B√¢timent

**1. Modifier `src/pipeline/generator/energy_cons_generator.py`:**

```python
BUILDINGS = [
    # ... existants
    {"id": 18, "name": "NewBuilding", "base_load": 2.5, "peak_multiplier": 1.8}
]
```

**2. Re-g√©n√©rer donn√©es historiques:**

```bash
docker exec renewstation-airflow-scheduler \
  python -c "from src.pipeline.generator.energy_cons_generator import generate_energy_consumption; generate_energy_consumption()"
```

**3. Re-train mod√®le:**

```bash
docker exec renewstation-airflow-scheduler \
  python -m src.pipeline.ml.train_energy_model
```

### Ajouter une Nouvelle Feature ML

**1. Modifier `src/pipeline/ml/train_energy_model.py`:**

```python
# Ajouter feature
df['new_feature'] = df['temperature_2m'] * df['humidity']

# Ajouter dans features list
features = [
    # ... existants
    'new_feature'
]
```

**2. Re-train:**

```bash
docker exec renewstation-airflow-scheduler \
  python -m src.pipeline.ml.train_energy_model
```

### Cr√©er un Nouvel Endpoint API

**1. Ajouter controller dans `api/src/controllers/solar.controller.js`:**

```javascript
exports.getCustomMetric = async (req, res) => {
  try {
    const result = await db.query('SELECT * FROM custom_table');
    res.json(result.rows);
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch custom metric' });
  }
};
```

**2. Ajouter route dans `api/src/routes/solar.routes.js`:**

```javascript
router.get('/custom-metric', solarController.getCustomMetric);
```

**3. Documenter dans README**

### Cr√©er une Nouvelle Page Dashboard

**1. Cr√©er composant `frontend/src/Pages/CustomPage.jsx`:**

```jsx
import React, { useState, useEffect } from 'react';

function CustomPage() {
  const [data, setData] = useState([]);

  useEffect(() => {
    fetch(`${import.meta.env.VITE_API_URL}/api/solar/custom-metric`)
      .then(res => res.json())
      .then(setData);
  }, []);

  return (
    <div className="p-6">
      <h1 className="text-2xl font-bold mb-4">Custom Metric</h1>
      {/* Votre visualisation */}
    </div>
  );
}

export default CustomPage;
```

**2. Ajouter route dans `frontend/src/App.jsx`:**

```jsx
import CustomPage from './Pages/CustomPage';

function App() {
  return (
    <Router>
      <Routes>
        {/* ... routes existantes */}
        <Route path="/custom" element={<CustomPage />} />
      </Routes>
    </Router>
  );
}
```

---

## üîí S√©curit√© & Best Practices

### Checklist S√©curit√© Production

- [ ] Changer tous les mots de passe par d√©faut
- [ ] Utiliser des secrets externes (Vault, AWS Secrets Manager)
- [ ] Activer SSL/TLS (Let's Encrypt)
- [ ] Firewall restrictif (UFW ou Security Groups)
- [ ] Ne PAS exposer PostgreSQL/Airflow publiquement
- [ ] Limiter rate API (nginx rate limiting)
- [ ] Logs centralis√©s avec rotation
- [ ] Backups automatis√©s quotidiens
- [ ] Monitoring avec alertes
- [ ] Updates r√©guli√®res Docker images
- [ ] Scanner vuln√©rabilit√©s (Trivy, Snyk)

### Variables Sensibles

**NE JAMAIS commit dans Git:**
- `.env`
- `api/.env`
- `*.pkl` (mod√®les ML si propri√©taires)
- Certificats SSL
- Backups

**Utiliser `.gitignore`:**

```
.env
api/.env
*.pkl
backups/
logs/
*.pem
*.key
```

---



**Derni√®re mise √† jour:** Novembre 2025  
**Version:** 3.0.0